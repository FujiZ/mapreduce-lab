\begin{document}

\section*{基本解决方法和设计思路}

\subsection*{NCA模型训练}

对于NCA，我们拟采用组合式MapReduce计算作业来实现。
由于梯度下降法需要用迭代方法求得逼近结果，
因此在NCA的主控程序中，需要使用一个循环来控制MapReduce作业的执行，
直到第$n$次迭代后结果与第$n-1$次的结果小于某个指定的阈值时结束，
或者通过经验值可确定在运行一定的次数后能得到接近的最终结果，
也可以控制循环固定的次数。

对于梯度下降中需要求解的变量，
我们采用顺序组合式MapReduce作业来依次计算：
首先我们可以通过DataJoin对集合$X$做笛卡尔积，
进而可以计算出$x_{ij}$；
在此基础上以$x_{ij}$作为输入，我们可以进一步计算出中间结果
$\exp(\lVert Ax_{i} - Ax_{j} \rVert^2)$，
其中矩阵$A$作为Distributed Cache在Mapper的setup()阶段读入；
基于以上结果，我们可以通过MapReduce对所有$i$计算出
$\sum_{k \neq i} \exp(\lVert Ax_{i} - Ax_{k} \rVert^2)$，
通过DataJoin连接上述两个中间结果，我们可以计算出$p_{ij}$。

$p_i$的计算需要考虑$x_j$与$x_i$的label是否相同。
我们可以在上述的每个中间结果后加上$x_i$与$x_j$的label，
并通过Mapper过滤掉与$x_i$label不同的元素，
在Reducer端只需做简单的求和即可。

基于以上数据，我们可以对梯度$\frac{\partial f}{\partial A}$进行求解。
我们首先使用DataJoin计算出中间结果$p_{ij} x_{ij} x_{ij}^\top$，
然后使用不同的Mapper过滤元素，分别计算
$\sum_{k} p_{ik} x_{ik} x_{ik}^\top$以及$\sum_{j \in C_i} p_{ij} x_{ij} x_{ij}^\top$，
需要注意的是由于这两者的计算没有依赖关系，所以可以通过配置Job使它们并行执行。
在计算出以上两个求和的结果后，
梯度$\frac{\partial f}{\partial A}$可以通过简单的操作得出，这里不做赘述。
在每次迭代的最后，我们利用当前位置的梯度对矩阵$A$进行更新，并启动下一次迭代。

\subsection*{KNN最近邻分类算法}

为了验证NCA模型训练的结果，我们使用KNN来进行分类预测。
关于KNN最近邻分类算法，在书上已经有了比较详细的介绍，
并且也给出了MapReduce的实现方法。
我们对其所做的改动是使用NCA训练出的模型作为其距离度量。

\end{document}
